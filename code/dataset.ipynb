{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.原始数据分类\n",
    "1. 导入需要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 根据.xml文件对原始数据集'PMID2019/JPEGImages/'进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\86159\\OneDrive - bjfu.edu.cn\\大创打工人\\CVAI\\code\n"
     ]
    }
   ],
   "source": [
    "# 定义路径\n",
    "print(os.getcwd())\n",
    "xml_folder = '../OriginalData/PMID2019/Annotations'\n",
    "image_folder = '../OriginalData/PMID2019/JPEGImages'\n",
    "test_set_path = '../dataset/test'\n",
    "train_set_path = '../dataset/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folders_and_move_images(xml_folder, image_folder, train_set_path):\n",
    "    # 清空目标目录\n",
    "    if os.path.exists(test_set_path):\n",
    "        shutil.rmtree(test_set_path)\n",
    "    if os.path.exists(train_set_path):\n",
    "        shutil.rmtree(train_set_path)\n",
    "\n",
    "    # 遍历XML文件夹\n",
    "    for xml_file in os.listdir(xml_folder):\n",
    "        if not xml_file.endswith('.xml'):\n",
    "            continue\n",
    "\n",
    "        # 解析XML文件\n",
    "        tree = ET.parse(os.path.join(xml_folder, xml_file))\n",
    "        root = tree.getroot()\n",
    "\n",
    "        # 提取\"name\"字段值\n",
    "        name = root.find('.//name').text\n",
    "\n",
    "        # 创建对应的文件夹\n",
    "        train_class_folder = os.path.join(train_set_path, name)\n",
    "\n",
    "        os.makedirs(train_class_folder, exist_ok=True)\n",
    "\n",
    "        # 获取与当前XML文件对应的图片文件\n",
    "        image_file = xml_file.replace('.xml', '.jpg')\n",
    "\n",
    "        # 如果对应的图片文件存在，则将其移动到训练集文件夹\n",
    "        if os.path.exists(os.path.join(image_folder, image_file)):\n",
    "            shutil.copy(os.path.join(image_folder, image_file), os.path.join(train_class_folder, image_file))\n",
    "            print(f\"'{image_file}' Succeeded.\")\n",
    "        else:\n",
    "            print(f\"Image file '{image_file}' not found for XML file '{xml_file}'.\")\n",
    "                \n",
    "\n",
    "\n",
    "# 创建文件夹并移动图片\n",
    "# create_folders_and_move_images(xml_folder, image_folder, train_set_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 从```'dataset/train/'```中按比例(```split_ratio=0.2```)划分测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_files_to_test_set(train_set_path, test_set_path, classes, split_ratio=0.2):\n",
    "    \"\"\"\n",
    "    将训练集中的部分文件移动到测试集中\n",
    "    \n",
    "    参数：\n",
    "    train_set_path: 训练集文件夹路径\n",
    "    test_set_path: 测试集文件夹路径\n",
    "    classes: 类别列表\n",
    "    split_ratio: 测试集占比，默认为0.2\n",
    "    \"\"\"\n",
    "    # 清空目标目录\n",
    "    if os.path.exists(test_set_path):\n",
    "        shutil.rmtree(test_set_path)\n",
    "\n",
    "    # 遍历每个类别\n",
    "    for class_name in classes:\n",
    "        class_train_path = os.path.join(train_set_path, class_name)\n",
    "        class_test_path = os.path.join(test_set_path, class_name)\n",
    "\n",
    "        \n",
    "\n",
    "        os.makedirs(class_test_path, exist_ok=True)\n",
    "\n",
    "        # 获取类别下的所有文件\n",
    "        files = [file for file in os.listdir(class_train_path) if file.endswith('.jpg')]\n",
    "\n",
    "        # 计算要移动到测试集的文件数量\n",
    "        num_files_to_move = int(len(files) * split_ratio)\n",
    "\n",
    "        # 随机选择要移动的文件\n",
    "        files_to_move = random.sample(files, num_files_to_move)\n",
    "\n",
    "        # 移动文件到测试集中\n",
    "        for file_to_move in files_to_move:\n",
    "            shutil.move(os.path.join(class_train_path, file_to_move), os.path.join(class_test_path, file_to_move))\n",
    "\n",
    "# move_files_to_test_set(train_set_path, test_set_path, os.listdir(train_set_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.根据划分后的文件夹构建数据集\n",
    "#### 1. 导入需要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torch.utils.data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 构造dataset类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(os.listdir(root_dir))\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for cls_name in self.classes:\n",
    "            cls_folder = os.path.join(root_dir, cls_name)\n",
    "            for img_name in os.listdir(cls_folder):\n",
    "                img_path = os.path.join(cls_folder, img_name)\n",
    "                self.image_paths.append(img_path)\n",
    "                self.labels.append(self.class_to_idx[cls_name])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 第一次定义transform、创建DataLoader对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义图像转换（只转换为Tensor，不做其他变换）\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # 调整大小\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 创建自定义数据集实例\n",
    "# dataset = CustomDataset(root_dir='../dataset/train', transform=transform)\n",
    "# dataloader = DataLoader(dataset, batch_size=10, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 计算图像各通道均值和标准差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def calculate_channel_mean_std(dataloader):\n",
    "    \"\"\"\n",
    "    计算图像数据集的各通道均值和标准差\n",
    "\n",
    "    Args:\n",
    "        dataloader: 包含图像数据的dataloader\n",
    "\n",
    "    Returns:\n",
    "        各通道均值和标准差的元组，形如(channel_mean, channel_std)\n",
    "    \"\"\"\n",
    "    num_channels = 3  # 假设通道数为3\n",
    "\n",
    "    # 初始化通道总和和像素总数\n",
    "    channel_sum = torch.zeros(num_channels)\n",
    "    channel_sum_sq = torch.zeros(num_channels)\n",
    "    pixel_count = 0\n",
    "\n",
    "     # 遍历dataloader计算累加均值和标准差\n",
    "    for images, _ in dataloader:\n",
    "        print(channel_sum)\n",
    "        # 累加每个通道的总和\n",
    "        channel_sum += torch.sum(images, dim=(0, 2, 3))\n",
    "\n",
    "        # 累加每个通道的平方和\n",
    "        channel_sum_sq += torch.sum(images ** 2, dim=(0, 2, 3))\n",
    "\n",
    "        # 计算像素总数\n",
    "        pixel_count += images.size(0) * images.size(2) * images.size(3)\n",
    "\n",
    "    # 计算均值\n",
    "    channel_mean = channel_sum / pixel_count\n",
    "\n",
    "    # 计算标准差\n",
    "    channel_std = torch.sqrt(channel_sum_sq / pixel_count - channel_mean ** 2)\n",
    "\n",
    "    return channel_mean, channel_std\n",
    "\n",
    "# 示例用法\n",
    "# channel_mean, channel_std = calculate_channel_mean_std(dataloader)\n",
    "# print(\"各通道均值：\", channel_mean)\n",
    "# print(\"各通道标准差：\", channel_std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 使用计算出的结果再次构建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设计算得到的均值和标准差如下\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# 定义图像转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  # 随机水平翻转\n",
    "    transforms.ToTensor(),  # 转换为Tensor\n",
    "    # transforms.Normalize(mean, std)  # 使用计算得到的均值和标准差进行标准化\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "# 创建自定义数据集实例\n",
    "train_dataset = CustomDataset(root_dir='../dataset/train', transform=transform)\n",
    "test_dataset = CustomDataset(root_dir='../dataset/test', transform=transform)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.构建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=4096, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=24, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes=24):\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # 计算经过两次卷积和一次池化后的特征图尺寸\n",
    "        # 输入尺寸: 64*64\n",
    "        # 第一次卷积: (64 - 3 + 2 * 1) / 1 + 1 = 64\n",
    "        # 池化后: 64 / 2 = 32\n",
    "        # 第二次卷积: (32 - 3 + 2 * 1) / 1 + 1 = 32\n",
    "        # 池化后: 32 / 2 = 16\n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 16 * 16, 128)  # 注意：这里输入的尺寸是根据输入图像的分辨率计算得到的\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)  # num_classes 是数据集中的类别数量\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 16 * 16)  # 展平特征图以输入全连接层\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# 示例用法\n",
    "model = MyModel(num_classes=24)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.训练网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "print(device)\n",
    "# model.to(device)\n",
    "model.conv1.to(device)\n",
    "model.pool.to(device)\n",
    "model.conv2.to(device)\n",
    "model.fc1.to(device)\n",
    "model.fc2.to(device)\n",
    "model.fc3.to(device)\n",
    "\n",
    "# 初始化 GradScaler\n",
    "scaler = GradScaler()\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 前向传播和反向传播使用 autocast 进行混合精度计算\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}')\n",
    "    \n",
    "    # 验证模型\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Validation Accuracy: {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.测试网络\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
